{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Classification Model - SOLUTION\n\n**Instructor Solution Notebook**\n\nThis notebook contains the complete solution for the classification problem using the **Customer Churn Dataset**.\n\n---\n\n## Table of Contents\n1. [Setup & Imports](#setup)\n2. [Data Loading & Exploration](#data-loading)\n3. [Data Engineering](#data-engineering)\n4. [Model Training](#model-training)\n5. [Model Evaluation](#model-evaluation)\n6. [Model Saving](#model-saving)\n7. [Conclusions](#conclusions)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Imports <a id='setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Helper modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_engineering import *\n",
    "from model_utils import *\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading & Exploration <a id='data-loading'></a>\n",
    "\n",
    "### 2.1 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# SOLUTION: Using Customer Churn Dataset\nDATA_PATH = '../data/raw/customer_churn.csv'\n\n# Load data\ndf = load_data(DATA_PATH)\n\n# Display first few rows\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "print(f\"Dataset Shape: {df.shape[0]} rows, {df.shape[1]} columns\\n\")\n",
    "\n",
    "# Column information\n",
    "print(\"Column Information:\")\n",
    "print(df.info())\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Identify Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# SOLUTION: Target column for Customer Churn dataset\nTARGET_COLUMN = 'churn'\n\n# Check target distribution\nprint(f\"Target Variable: {TARGET_COLUMN}\")\nprint(f\"\\nValue Counts:\")\nprint(df[TARGET_COLUMN].value_counts())\nprint(f\"\\nPercentage Distribution:\")\nprint(df[TARGET_COLUMN].value_counts(normalize=True) * 100)\n\n# Visualize target distribution\nplt.figure(figsize=(8, 5))\ndf[TARGET_COLUMN].value_counts().plot(kind='bar', color=['#2ecc71', '#e74c3c'])\nplt.title(f'Distribution of {TARGET_COLUMN}')\nplt.xlabel(TARGET_COLUMN)\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nplt.show()\n\n# Check for class imbalance\nimbalance_ratio = df[TARGET_COLUMN].value_counts().min() / df[TARGET_COLUMN].value_counts().max()\nprint(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.3f}\")\nif imbalance_ratio < 0.5:\n    print(\"âš ï¸ Dataset is imbalanced. We'll need to handle this!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing_summary = check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Identify Feature Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Identify feature types\n",
    "feature_types = get_feature_types(df)\n",
    "\n",
    "numerical_features = feature_types['numerical']\n",
    "categorical_features = feature_types['categorical']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Engineering <a id='data-engineering'></a>\n",
    "\n",
    "### 3.1 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Handle missing values if any\n",
    "if len(missing_summary) > 0:\n",
    "    df = handle_missing_values(df, strategy='median')\n",
    "else:\n",
    "    print(\"No missing values to handle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Drop customer_id as it's not useful for prediction\n",
    "columns_to_drop = ['customer_id'] if 'customer_id' in df.columns else []\n",
    "\n",
    "if columns_to_drop:\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    print(f\"Dropped columns: {columns_to_drop}\")\n",
    "\n",
    "print(f\"\\nRemaining columns: {df.shape[1]}\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Encode categorical variables\n",
    "# Update categorical features list after dropping columns\n",
    "categorical_features = [col for col in df.select_dtypes(include=['object']).columns \n",
    "                       if col != TARGET_COLUMN]\n",
    "\n",
    "if categorical_features:\n",
    "    print(f\"Encoding categorical features: {categorical_features}\")\n",
    "    df = encode_categorical(df, categorical_features, method='onehot')\n",
    "else:\n",
    "    print(\"No categorical features to encode\")\n",
    "\n",
    "print(f\"\\nShape after encoding: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Separate Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Separate X and y\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns ({len(X.columns)}):\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Create train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = create_train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Verify class distribution\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Scale features using StandardScaler\n",
    "X_train_scaled, X_test_scaled, scaler = scale_features(\n",
    "    X_train, X_test, \n",
    "    method='standard'\n",
    ")\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "print(\"\\nFeatures scaled successfully!\")\n",
    "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Apply SMOTE if dataset is imbalanced\n",
    "imbalance_ratio = y_train.value_counts().min() / y_train.value_counts().max()\n",
    "\n",
    "if imbalance_ratio < 0.5:\n",
    "    print(\"Applying SMOTE to handle class imbalance...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "    \n",
    "    print(f\"Original training set: {X_train_scaled.shape[0]} samples\")\n",
    "    print(f\"Resampled training set: {X_train_resampled.shape[0]} samples\")\n",
    "    print(f\"\\nClass distribution after SMOTE:\")\n",
    "    print(pd.Series(y_train_resampled).value_counts())\n",
    "    \n",
    "    X_train_final = X_train_resampled\n",
    "    y_train_final = y_train_resampled\n",
    "else:\n",
    "    print(\"Class balance is acceptable, no SMOTE needed\")\n",
    "    X_train_final = X_train_scaled\n",
    "    y_train_final = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Training <a id='model-training'></a>\n",
    "\n",
    "### 4.1 Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train three classification models\n",
    "trained_models = train_classification_models(X_train_final, y_train_final)\n",
    "\n",
    "print(\"\\nAll models trained successfully!\")\n",
    "print(f\"Models: {list(trained_models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Compare Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Compare all models\n",
    "comparison_df = compare_classification_models(trained_models, X_test_scaled, y_test)\n",
    "\n",
    "# Display comparison\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Select Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Select best model based on F1 score\n",
    "best_model_name = comparison_df.loc[comparison_df['f1'].idxmax(), 'Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"âœ… Best Model: {best_model_name}\")\n",
    "print(f\"\\nBest Model Metrics:\")\n",
    "print(comparison_df[comparison_df['Model'] == best_model_name].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Evaluation <a id='model-evaluation'></a>\n",
    "\n",
    "### 5.1 Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Get predictions and detailed evaluation\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\"Classification Report - {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Plot confusion matrix\n",
    "plot_confusion_matrix(best_model, X_test_scaled, y_test, best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Plot ROC curve\n",
    "plot_roc_curve(best_model, X_test_scaled, y_test, best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Get and plot feature importance\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance_df = get_feature_importance(\n",
    "        best_model, \n",
    "        X_train_final.columns if isinstance(X_train_final, pd.DataFrame) else X_train_scaled.columns, \n",
    "        top_n=10\n",
    "    )\n",
    "else:\n",
    "    print(f\"{best_model_name} does not have feature importance attribute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Model Saving <a id='model-saving'></a>\n",
    "\n",
    "### 6.1 Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Save best model\n",
    "model_filename = f\"../models/classification_{best_model_name.lower().replace(' ', '_')}.pkl\"\n",
    "save_model(best_model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Save Preprocessing Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Save scaler\n",
    "import joblib\n",
    "joblib.dump(scaler, '../models/scaler_classification.pkl')\n",
    "print(\"âœ… Scaler saved to ../models/scaler_classification.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Save Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Save comparison results\n",
    "comparison_df.to_csv('../models/classification_model_comparison.csv', index=False)\n",
    "print(\"âœ… Model comparison saved to ../models/classification_model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Conclusions <a id='conclusions'></a>\n",
    "\n",
    "### Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## SOLUTION SUMMARY\n\n### 1. Dataset\n- Used **Customer Churn Dataset** with ~10,000 customers\n- Target: Predict whether a customer will churn (leave the service)\n\n### 2. Data Challenges\n- **Class Imbalance**: Dataset was imbalanced (minority class < 30%)\n- **Solution**: Applied SMOTE to balance training data\n- **Categorical Features**: Encoded country and gender using one-hot encoding\n- **Feature Scaling**: Applied StandardScaler for numerical features\n\n### 3. Best Model\n- **Winner**: Random Forest or XGBoost (typically performs best)\n- **Why**: Better handles non-linear relationships and feature interactions\n- Tree-based models naturally handle different feature scales\n\n### 4. Key Metrics\nExpected performance:\n- **Accuracy**: 82-86%\n- **Precision**: 75-80%\n- **Recall**: 70-75%\n- **F1 Score**: 72-77%\n- **ROC-AUC**: 0.85-0.90\n\n### 5. Important Features\nTop predictors of churn (typical findings):\n1. **Age** - Older customers more likely to churn\n2. **Number of Products** - Customers with 1 product more likely to churn\n3. **Balance** - Very high or very low balance indicates churn risk\n4. **Active Member** - Inactive members much more likely to churn\n5. **Geography** - Location impacts churn rates\n\n### 6. Model Limitations\n- Model may struggle with edge cases (very young/old customers)\n- Cannot capture temporal patterns (no time-series features)\n- May have false positives for loyal customers with unusual patterns\n- Performance depends heavily on feature quality\n\n### 7. Business Insights\n- Focus retention efforts on inactive customers\n- Customers with only 1 product are high risk\n- Age-specific retention strategies may be beneficial\n- Geography-based campaigns could improve retention\n\n### 8. Next Steps\n1. **Feature Engineering**: Create interaction features (age Ã— products, balance Ã— tenure)\n2. **Hyperparameter Tuning**: Grid search for optimal parameters\n3. **Ensemble Methods**: Combine multiple models\n4. **Cost-Sensitive Learning**: Assign higher cost to false negatives\n5. **Deployment**: Deploy to H2O for production use\n6. **Monitoring**: Track model performance over time"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Verify model can be loaded and used\n",
    "loaded_model = load_model(model_filename)\n",
    "\n",
    "# Test prediction\n",
    "test_prediction = loaded_model.predict(X_test_scaled[:5])\n",
    "test_proba = loaded_model.predict_proba(X_test_scaled[:5])[:, 1]\n",
    "\n",
    "print(f\"\\nTest predictions: {test_prediction}\")\n",
    "print(f\"Prediction probabilities: {test_proba}\")\n",
    "print(f\"Actual values: {y_test[:5].values}\")\n",
    "print(\"\\nâœ… Model loaded and tested successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ‰ Solution Complete!\n",
    "\n",
    "This solution demonstrates:\n",
    "- âœ… Complete data preprocessing workflow\n",
    "- âœ… Handling class imbalance with SMOTE\n",
    "- âœ… Training and comparing multiple models\n",
    "- âœ… Comprehensive model evaluation\n",
    "- âœ… Proper model packaging and saving\n",
    "- âœ… Business insights and recommendations\n",
    "\n",
    "**Expected Student Outcomes:**\n",
    "- Similar results with their chosen dataset\n",
    "- Understanding of complete ML workflow\n",
    "- Ability to interpret and explain results\n",
    "- Ready for deployment phase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}