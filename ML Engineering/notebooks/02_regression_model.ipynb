{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Regression Model - FintelHub Capstone\n\n**Objective**: Build and evaluate a regression model to predict continuous values in financial data.\n\n**Choose Your Problem:**\n- **Option A**: Transaction Amount Prediction (PaySim dataset)\n- **Option B**: Loan Amount Prediction (Credit Risk dataset)\n- **Option C**: Balance/Credit Score Prediction (Customer Churn or Credit Risk dataset)\n\n---\n\n## Table of Contents\n1. [Setup & Imports](#setup)\n2. [Data Loading & Exploration](#data-loading)\n3. [Data Engineering](#data-engineering)\n4. [Model Training](#model-training)\n5. [Model Evaluation](#model-evaluation)\n6. [Model Saving](#model-saving)\n7. [Conclusions](#conclusions)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Imports <a id='setup'></a>\n",
    "\n",
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Helper modules (in src folder)\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_engineering import *\n",
    "from model_utils import *\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 2. Data Loading & Exploration <a id='data-loading'></a>\n\n### 2.1 Load Dataset\n\n**Instructions**: Update the file path based on your chosen dataset:\n- Transaction Amount: `'../data/raw/fraud_data.csv'`\n- Loan Amount: `'../data/raw/credit_risk.csv'`\n- Balance: `'../data/raw/customer_churn.csv'`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update with your chosen dataset path\n",
    "DATA_PATH = '../data/raw/credit_risk.csv'  # Change this!\n",
    "\n",
    "# Load data (limit rows for large datasets)\n",
    "df = load_data(DATA_PATH, nrows=None)\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basic Data Exploration (GUIDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "print(f\"Dataset Shape: {df.shape[0]} rows, {df.shape[1]} columns\\n\")\n",
    "\n",
    "# Column information\n",
    "print(\"Column Information:\")\n",
    "print(df.info())\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Identify Target Variable\n",
    "\n",
    "**Target Variable Names (choose what to predict):**\n",
    "- Transaction Amount: `amount`\n",
    "- Loan Amount: `loan_amnt`\n",
    "- Balance: `balance`\n",
    "- Income: `person_income`, `estimated_salary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set your target column name\n",
    "TARGET_COLUMN = 'loan_amnt'  # Change this based on your dataset!\n",
    "\n",
    "# Check target distribution\n",
    "print(f\"Target Variable: {TARGET_COLUMN}\")\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(df[TARGET_COLUMN].describe())\n",
    "\n",
    "# Visualize target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df[TARGET_COLUMN], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel(TARGET_COLUMN)\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title(f'Distribution of {TARGET_COLUMN}')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Boxplot\n",
    "axes[1].boxplot(df[TARGET_COLUMN])\n",
    "axes[1].set_ylabel(TARGET_COLUMN)\n",
    "axes[1].set_title(f'Boxplot of {TARGET_COLUMN}')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for outliers\n",
    "Q1 = df[TARGET_COLUMN].quantile(0.25)\n",
    "Q3 = df[TARGET_COLUMN].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = ((df[TARGET_COLUMN] < (Q1 - 1.5 * IQR)) | (df[TARGET_COLUMN] > (Q3 + 1.5 * IQR))).sum()\n",
    "print(f\"\\nNumber of outliers: {outliers} ({outliers/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Check for Missing Values (GUIDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing_summary = check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Identify Feature Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the helper function to identify numerical and categorical features\n",
    "feature_types = get_feature_types(df)\n",
    "\n",
    "numerical_features = feature_types['numerical']\n",
    "categorical_features = feature_types['categorical']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Correlation Analysis (GUIDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target variable\n",
    "correlations = df[numerical_features].corr()[TARGET_COLUMN].sort_values(ascending=False)\n",
    "print(\"Correlation with target variable:\")\n",
    "print(correlations)\n",
    "\n",
    "# Visualize top correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlations.drop(TARGET_COLUMN).plot(kind='barh')\n",
    "plt.xlabel('Correlation with Target')\n",
    "plt.title(f'Feature Correlations with {TARGET_COLUMN}')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Checkpoint 1\n",
    "Before proceeding, ensure:\n",
    "- âœ… Data is loaded successfully\n",
    "- âœ… You understand the target variable distribution\n",
    "- âœ… You've identified missing values (if any)\n",
    "- âœ… You know which features are numerical vs categorical\n",
    "- âœ… You've examined correlations with target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Engineering <a id='data-engineering'></a>\n",
    "\n",
    "### 3.1 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle missing values if any were found\n",
    "# Choose strategy: 'mean', 'median', 'mode', or 'drop'\n",
    "\n",
    "if len(missing_summary) > 0:\n",
    "    # Example: Fill numerical columns with median\n",
    "    df = handle_missing_values(df, strategy='median')\n",
    "else:\n",
    "    print(\"No missing values to handle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Drop Irrelevant Columns\n",
    "\n",
    "**Common columns to drop:**\n",
    "- ID columns\n",
    "- Timestamp columns\n",
    "- Columns with data leakage (e.g., future information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Drop irrelevant columns\n",
    "columns_to_drop = []  # Add column names here\n",
    "\n",
    "if columns_to_drop:\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    print(f\"Dropped columns: {columns_to_drop}\")\n",
    "\n",
    "print(f\"\\nRemaining columns: {df.shape[1]}\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Handle Outliers (Optional)\n",
    "\n",
    "Be careful with outliers in regression - they might be legitimate extreme values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove outliers if necessary\n",
    "# Uncomment and modify if needed\n",
    "\n",
    "# columns_to_check = [TARGET_COLUMN]  # Add other columns if needed\n",
    "# df = remove_outliers(df, columns_to_check, method='iqr', threshold=1.5)\n",
    "\n",
    "print(f\"Current dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Encode categorical variables\n",
    "# Update categorical_features list if you dropped any columns\n",
    "\n",
    "# Remove target column from categorical features if present\n",
    "if TARGET_COLUMN in categorical_features:\n",
    "    categorical_features.remove(TARGET_COLUMN)\n",
    "\n",
    "if categorical_features:\n",
    "    print(f\"Encoding categorical features: {categorical_features}\")\n",
    "    df = encode_categorical(df, categorical_features, method='onehot')\n",
    "else:\n",
    "    print(\"No categorical features to encode\")\n",
    "\n",
    "print(f\"\\nShape after encoding: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Separate Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Separate features (X) and target (y)\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns ({len(X.columns)}):\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Train-Test Split (GUIDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% training, 20% testing\n",
    "# No stratification needed for regression\n",
    "X_train, X_test, y_train, y_test = create_train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Check target distribution in both sets\n",
    "print(f\"\\nTraining target - Mean: {y_train.mean():.2f}, Std: {y_train.std():.2f}\")\n",
    "print(f\"Test target - Mean: {y_test.mean():.2f}, Std: {y_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Scale numerical features\n",
    "X_train_scaled, X_test_scaled, scaler = scale_features(\n",
    "    X_train, X_test, \n",
    "    method='standard'\n",
    ")\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "print(\"\\nFeatures scaled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Checkpoint 2\n",
    "Before proceeding to modeling, verify:\n",
    "- âœ… Missing values are handled\n",
    "- âœ… Outliers are addressed (if needed)\n",
    "- âœ… Categorical variables are encoded\n",
    "- âœ… Data is split into train/test sets\n",
    "- âœ… Features are scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Training <a id='model-training'></a>\n",
    "\n",
    "### 4.1 Train Multiple Models (GUIDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train four regression models\n",
    "trained_models = train_regression_models(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nAll models trained successfully!\")\n",
    "print(f\"Models: {list(trained_models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Compare Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare all models and create comparison dataframe\n",
    "comparison_df = compare_regression_models(trained_models, X_test_scaled, y_test)\n",
    "\n",
    "# Display comparison\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Select Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select best model based on RÂ² score (or RMSE)\n",
    "# Higher RÂ² is better, Lower RMSE is better\n",
    "\n",
    "best_model_name = comparison_df.loc[comparison_df['r2'].idxmax(), 'Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"âœ… Best Model: {best_model_name}\")\n",
    "print(f\"\\nBest Model Metrics:\")\n",
    "print(comparison_df[comparison_df['Model'] == best_model_name].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Evaluation <a id='model-evaluation'></a>\n",
    "\n",
    "### 5.1 Detailed Evaluation of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Detailed Evaluation - {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE):      {mae:.4f}\")\n",
    "print(f\"RÂ² Score:                       {r2:.4f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"- On average, predictions are off by {mae:.2f} units\")\n",
    "print(f\"- Model explains {r2*100:.2f}% of the variance in the target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Actual vs Predicted Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot actual vs predicted values\n",
    "plot_predictions(y_test, y_pred, best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot residuals\n",
    "plot_residuals(y_test, y_pred, best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Error Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction errors\n",
    "errors = y_test - y_pred\n",
    "percent_errors = (errors / y_test) * 100\n",
    "\n",
    "print(\"Error Analysis:\")\n",
    "print(f\"Mean Error: {errors.mean():.4f}\")\n",
    "print(f\"Std Error: {errors.std():.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error: {np.abs(percent_errors).mean():.2f}%\")\n",
    "\n",
    "# Find worst predictions\n",
    "worst_predictions = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Error': np.abs(errors)\n",
    "}).sort_values('Error', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Worst Predictions:\")\n",
    "print(worst_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get and plot feature importance (for tree-based models)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance_df = get_feature_importance(\n",
    "        best_model, \n",
    "        X_train_scaled.columns, \n",
    "        top_n=10\n",
    "    )\n",
    "else:\n",
    "    print(f\"{best_model_name} does not have feature importance attribute\")\n",
    "    print(\"\\nFor Linear/Ridge models, you can examine coefficients:\")\n",
    "    if hasattr(best_model, 'coef_'):\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Feature': X_train_scaled.columns,\n",
    "            'Coefficient': best_model.coef_\n",
    "        }).sort_values('Coefficient', key=abs, ascending=False)\n",
    "        print(coef_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Model Saving <a id='model-saving'></a>\n",
    "\n",
    "### 6.1 Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save your best model\n",
    "model_filename = f\"../models/regression_{best_model_name.lower().replace(' ', '_')}.pkl\"\n",
    "save_model(best_model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Save Preprocessing Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save scaler for use in production\n",
    "import joblib\n",
    "joblib.dump(scaler, '../models/scaler_regression.pkl')\n",
    "print(\"âœ… Scaler saved to ../models/scaler_regression.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Save Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison results\n",
    "comparison_df.to_csv('../models/regression_model_comparison.csv', index=False)\n",
    "print(\"âœ… Model comparison saved to ../models/regression_model_comparison.csv\")\n",
    "\n",
    "# Save predictions\n",
    "save_predictions(y_test, y_pred, '../models/regression_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Conclusions <a id='conclusions'></a>\n",
    "\n",
    "### 7.1 Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Write a brief summary of your findings**\n",
    "\n",
    "1. **Dataset**: [Describe which dataset you used]\n",
    "\n",
    "2. **Target Variable**: [What are you predicting?]\n",
    "\n",
    "3. **Data Challenges**: [Note any issues like outliers, correlations, etc.]\n",
    "\n",
    "4. **Best Model**: [State which model performed best and why]\n",
    "\n",
    "5. **Key Metrics**: \n",
    "   - RMSE: [value]\n",
    "   - MAE: [value]\n",
    "   - RÂ²: [value]\n",
    "\n",
    "6. **Prediction Accuracy**: [How accurate are the predictions? What's the average error?]\n",
    "\n",
    "7. **Important Features**: [List top 3-5 features that influenced predictions]\n",
    "\n",
    "8. **Model Limitations**: [Note any limitations, residual patterns, or concerns]\n",
    "\n",
    "9. **Next Steps**: [Suggest improvements or further analysis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Test Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify model can be loaded\n",
    "loaded_model = load_model(model_filename)\n",
    "\n",
    "# Test prediction\n",
    "test_prediction = loaded_model.predict(X_test_scaled[:5])\n",
    "print(f\"\\nTest predictions: {test_prediction}\")\n",
    "print(f\"Actual values: {y_test[:5].values}\")\n",
    "print(f\"Errors: {y_test[:5].values - test_prediction}\")\n",
    "print(\"\\nâœ… Model loaded and tested successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've successfully completed the Regression Model notebook!\n",
    "\n",
    "**Next Steps:**\n",
    "1. Review both classification and regression models\n",
    "2. Compare performance across different approaches\n",
    "3. Document your learnings\n",
    "4. Prepare for model deployment to H2O\n",
    "5. Consider advanced techniques (feature engineering, hyperparameter tuning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}