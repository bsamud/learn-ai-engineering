{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Structured Outputs\n",
    "\n",
    "**Get reliable JSON and structured data from LLMs.**\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Use JSON mode for structured responses\n",
    "- Validate outputs with Pydantic\n",
    "- Extract entities and data from text\n",
    "- Handle validation errors gracefully\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Why Structured Outputs?](#why)\n",
    "2. [JSON Mode](#json-mode)\n",
    "3. [Pydantic Validation](#pydantic)\n",
    "4. [Entity Extraction](#extraction)\n",
    "5. [Error Handling](#errors)\n",
    "6. [Exercises](#exercises)\n",
    "7. [Checkpoint](#checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Setup\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(Path.cwd().parent / \".env\")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Why Structured Outputs? <a id='why'></a>\n",
    "\n",
    "LLMs return free-form text, but applications need structured data:\n",
    "\n",
    "```\n",
    "LLM Response (text)          What You Need (data)\n",
    "─────────────────────        ─────────────────────\n",
    "\"The product costs $29.99    {\"product\": \"Widget\",\n",
    " and is available in blue     \"price\": 29.99,\n",
    " and red colors.\"             \"colors\": [\"blue\", \"red\"]}\n",
    "```\n",
    "\n",
    "### Challenges:\n",
    "- LLMs might include extra text\n",
    "- JSON might be malformed\n",
    "- Fields might be missing or wrong type\n",
    "- Format varies between requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. JSON Mode <a id='json-mode'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: OpenAI JSON mode\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Extract product info. Return JSON with: name, price, colors (array).\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"The SuperWidget Pro costs $49.99 and comes in black, silver, and gold.\"\n",
    "        }\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "# Parse the JSON response\n",
    "data = json.loads(response.choices[0].message.content)\n",
    "print(\"Extracted data:\")\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Anthropic structured output\n",
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic()\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=500,\n",
    "    system=\"\"\"Extract product information from the text.\n",
    "Return ONLY valid JSON with this structure:\n",
    "{\"name\": \"string\", \"price\": number, \"colors\": [\"string\"]}\"\"\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"The SuperWidget Pro costs $49.99 and comes in black, silver, and gold.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "data = json.loads(response.content[0].text)\n",
    "print(\"Extracted data:\")\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Pydantic Validation <a id='pydantic'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Define Pydantic models\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import Optional\n",
    "\n",
    "class Product(BaseModel):\n",
    "    \"\"\"Product information extracted from text.\"\"\"\n",
    "    name: str = Field(description=\"Product name\")\n",
    "    price: float = Field(ge=0, description=\"Price in USD\")\n",
    "    colors: list[str] = Field(default_factory=list, description=\"Available colors\")\n",
    "    in_stock: Optional[bool] = Field(default=None, description=\"Stock status\")\n",
    "    \n",
    "    @field_validator('name')\n",
    "    @classmethod\n",
    "    def name_not_empty(cls, v):\n",
    "        if not v.strip():\n",
    "            raise ValueError('Name cannot be empty')\n",
    "        return v.strip()\n",
    "\n",
    "# Test validation\n",
    "product = Product(\n",
    "    name=\"SuperWidget Pro\",\n",
    "    price=49.99,\n",
    "    colors=[\"black\", \"silver\", \"gold\"]\n",
    ")\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Validate LLM output with Pydantic\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import json\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int = Field(ge=0, le=150)\n",
    "    occupation: str\n",
    "    skills: list[str] = Field(default_factory=list)\n",
    "\n",
    "def extract_person(text: str) -> Person:\n",
    "    \"\"\"Extract person info from text with validation.\"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"Extract person information from text.\n",
    "Return JSON matching this schema: {Person.model_json_schema()}\"\"\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    data = json.loads(response.choices[0].message.content)\n",
    "    return Person(**data)  # Validate with Pydantic\n",
    "\n",
    "# Test it\n",
    "text = \"\"\"John Smith is a 35-year-old software engineer. \n",
    "He specializes in Python, machine learning, and cloud architecture.\"\"\"\n",
    "\n",
    "person = extract_person(text)\n",
    "print(f\"Name: {person.name}\")\n",
    "print(f\"Age: {person.age}\")\n",
    "print(f\"Occupation: {person.occupation}\")\n",
    "print(f\"Skills: {person.skills}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Entity Extraction <a id='extraction'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Extract multiple entities\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from enum import Enum\n",
    "\n",
    "class Priority(str, Enum):\n",
    "    LOW = \"low\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HIGH = \"high\"\n",
    "    CRITICAL = \"critical\"\n",
    "\n",
    "class Task(BaseModel):\n",
    "    title: str\n",
    "    description: Optional[str] = None\n",
    "    priority: Priority = Priority.MEDIUM\n",
    "    assignee: Optional[str] = None\n",
    "    deadline: Optional[str] = None\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    tasks: list[Task]\n",
    "\n",
    "def extract_tasks(meeting_notes: str) -> TaskList:\n",
    "    \"\"\"Extract tasks from meeting notes.\"\"\"\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    client = OpenAI()\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"Extract action items/tasks from meeting notes.\n",
    "Return JSON matching: {TaskList.model_json_schema()}\n",
    "Priority levels: low, medium, high, critical\"\"\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": meeting_notes}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    data = json.loads(response.choices[0].message.content)\n",
    "    return TaskList(**data)\n",
    "\n",
    "# Test with meeting notes\n",
    "notes = \"\"\"\n",
    "Team meeting 2024-01-15:\n",
    "\n",
    "- John will update the API documentation by Friday (high priority)\n",
    "- Sarah needs to fix the login bug ASAP - this is blocking users\n",
    "- We should clean up the test database sometime next week\n",
    "- Mike to prepare demo for the client meeting on Monday\n",
    "\"\"\"\n",
    "\n",
    "tasks = extract_tasks(notes)\n",
    "print(f\"Found {len(tasks.tasks)} tasks:\\n\")\n",
    "for task in tasks.tasks:\n",
    "    print(f\"[{task.priority.value.upper()}] {task.title}\")\n",
    "    if task.assignee:\n",
    "        print(f\"  Assignee: {task.assignee}\")\n",
    "    if task.deadline:\n",
    "        print(f\"  Deadline: {task.deadline}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Use our utility function\n",
    "from src.llm_utils import LLMClient, get_json_response\n",
    "\n",
    "client = LLMClient(provider=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "result = get_json_response(\n",
    "    client,\n",
    "    message=\"What are the 3 largest countries by area? Include name and area in sq km.\",\n",
    "    system=\"Return JSON with 'countries' array, each with 'name' and 'area_km2' fields.\"\n",
    ")\n",
    "\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Error Handling <a id='errors'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Robust extraction with retries\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "class ExtractedData(BaseModel):\n",
    "    company: str\n",
    "    revenue: float\n",
    "    year: int\n",
    "\n",
    "def extract_with_retry(\n",
    "    text: str,\n",
    "    model_class: type[BaseModel],\n",
    "    max_retries: int = 3\n",
    ") -> BaseModel:\n",
    "    \"\"\"Extract data with retry on validation failure.\"\"\"\n",
    "    client = OpenAI()\n",
    "    last_error = None\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Add error context on retry\n",
    "            error_context = \"\"\n",
    "            if last_error:\n",
    "                error_context = f\"\\n\\nPrevious attempt failed: {last_error}. Please fix.\"\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": f\"\"\"Extract data from text.\n",
    "Return JSON matching: {model_class.model_json_schema()}{error_context}\"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            data = json.loads(response.choices[0].message.content)\n",
    "            return model_class(**data)  # Validate\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            last_error = f\"Invalid JSON: {e}\"\n",
    "        except ValidationError as e:\n",
    "            last_error = f\"Validation failed: {e}\"\n",
    "    \n",
    "    raise ValueError(f\"Failed after {max_retries} attempts: {last_error}\")\n",
    "\n",
    "# Test it\n",
    "text = \"Acme Corp reported $5.2 billion in revenue for fiscal year 2023.\"\n",
    "\n",
    "try:\n",
    "    data = extract_with_retry(text, ExtractedData)\n",
    "    print(f\"Company: {data.company}\")\n",
    "    print(f\"Revenue: ${data.revenue:,.0f}\")\n",
    "    print(f\"Year: {data.year}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Extraction failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Exercises <a id='exercises'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Email Extractor\n",
    "\n",
    "Create a Pydantic model and extractor for email metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create Email model with: sender, recipient, subject, summary, sentiment\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Multi-format Extractor\n",
    "\n",
    "Build an extractor that works with different document types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create extractors for invoices, receipts, and contracts\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Checkpoint <a id='checkpoint'></a>\n",
    "\n",
    "Before moving on, verify:\n",
    "\n",
    "- [ ] You can use JSON mode with LLMs\n",
    "- [ ] You created Pydantic models for validation\n",
    "- [ ] You extracted structured data from text\n",
    "- [ ] You handled validation errors\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll learn about **Embeddings & Vectors** - the foundation of semantic search!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
