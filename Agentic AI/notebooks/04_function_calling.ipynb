{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Function Calling\n",
    "\n",
    "**Master production-ready function calling** across different LLM providers.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand OpenAI's function calling format\n",
    "- Understand Anthropic's tool use format\n",
    "- Handle multi-turn conversations with tools\n",
    "- Implement proper error handling\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [OpenAI Function Calling](#openai)\n",
    "2. [Anthropic Tool Use](#anthropic)\n",
    "3. [Multi-Turn Conversations](#multi-turn)\n",
    "4. [Error Handling](#errors)\n",
    "5. [Using Our LLM Client](#client)\n",
    "6. [Exercises](#exercises)\n",
    "7. [Checkpoint](#checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Setup\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(Path.cwd().parent / \".env\")\n",
    "\n",
    "# Import both clients\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# Check for Anthropic\n",
    "try:\n",
    "    from anthropic import Anthropic\n",
    "    anthropic_client = Anthropic()\n",
    "    has_anthropic = True\n",
    "except:\n",
    "    has_anthropic = False\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"  OpenAI: Available\")\n",
    "print(f\"  Anthropic: {'Available' if has_anthropic else 'Not configured'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Define some tools we'll use throughout\n",
    "\n",
    "def get_weather(location: str, unit: str = \"celsius\") -> dict:\n",
    "    \"\"\"Mock weather function.\"\"\"\n",
    "    import random\n",
    "    temps = {\"celsius\": random.randint(15, 30), \"fahrenheit\": random.randint(59, 86)}\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"temperature\": temps.get(unit, temps[\"celsius\"]),\n",
    "        \"unit\": unit,\n",
    "        \"condition\": random.choice([\"sunny\", \"cloudy\", \"rainy\"])\n",
    "    }\n",
    "\n",
    "def search_web(query: str, num_results: int = 3) -> list:\n",
    "    \"\"\"Mock search function.\"\"\"\n",
    "    return [\n",
    "        {\"title\": f\"Result 1 for: {query}\", \"url\": \"https://example.com/1\"},\n",
    "        {\"title\": f\"Result 2 for: {query}\", \"url\": \"https://example.com/2\"},\n",
    "        {\"title\": f\"Result 3 for: {query}\", \"url\": \"https://example.com/3\"}\n",
    "    ][:num_results]\n",
    "\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Safe calculation.\"\"\"\n",
    "    allowed = set('0123456789+-*/.() ')\n",
    "    if not all(c in allowed for c in expression):\n",
    "        return \"Error: Invalid expression\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except:\n",
    "        return \"Error: Could not evaluate\"\n",
    "\n",
    "# Map function names to functions\n",
    "FUNCTIONS = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"search_web\": search_web,\n",
    "    \"calculate\": calculate\n",
    "}\n",
    "\n",
    "print(\"Functions defined:\", list(FUNCTIONS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. OpenAI Function Calling <a id='openai'></a>\n",
    "\n",
    "OpenAI's format uses `tools` with `function` type definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: OpenAI tool definitions\n",
    "\n",
    "openai_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather for a location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City name, e.g., 'Tokyo' or 'New York'\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"Temperature unit\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Perform mathematical calculations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Math expression like '2 + 2' or '10 * 5'\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(openai_tools)} OpenAI tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Make a request with tools\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather in Paris?\"}\n",
    "    ],\n",
    "    tools=openai_tools,\n",
    "    tool_choice=\"auto\"  # or \"required\" to force tool use\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "print(\"Response:\")\n",
    "print(f\"  Content: {message.content}\")\n",
    "print(f\"  Tool Calls: {message.tool_calls}\")\n",
    "print(f\"  Finish Reason: {response.choices[0].finish_reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Handle the tool call\n",
    "\n",
    "if message.tool_calls:\n",
    "    for tool_call in message.tool_calls:\n",
    "        print(f\"\\nTool Call:\")\n",
    "        print(f\"  ID: {tool_call.id}\")\n",
    "        print(f\"  Function: {tool_call.function.name}\")\n",
    "        print(f\"  Arguments: {tool_call.function.arguments}\")\n",
    "        \n",
    "        # Parse arguments and call function\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "        func = FUNCTIONS[tool_call.function.name]\n",
    "        result = func(**args)\n",
    "        \n",
    "        print(f\"  Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Anthropic Tool Use <a id='anthropic'></a>\n",
    "\n",
    "Anthropic uses a slightly different format with `input_schema` instead of `parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Anthropic tool definitions\n",
    "\n",
    "anthropic_tools = [\n",
    "    {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather for a location\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"City name, e.g., 'Tokyo' or 'New York'\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"Temperature unit\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"calculate\",\n",
    "        \"description\": \"Perform mathematical calculations\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Math expression like '2 + 2' or '10 * 5'\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(anthropic_tools)} Anthropic tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Make a request with Anthropic\n",
    "\n",
    "if has_anthropic:\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        tools=anthropic_tools,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"What's the weather in London?\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"Response:\")\n",
    "    print(f\"  Stop Reason: {response.stop_reason}\")\n",
    "    \n",
    "    for block in response.content:\n",
    "        print(f\"  Block Type: {block.type}\")\n",
    "        if block.type == \"text\":\n",
    "            print(f\"    Text: {block.text}\")\n",
    "        elif block.type == \"tool_use\":\n",
    "            print(f\"    Tool: {block.name}\")\n",
    "            print(f\"    ID: {block.id}\")\n",
    "            print(f\"    Input: {block.input}\")\n",
    "else:\n",
    "    print(\"Anthropic not configured. Skipping this example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Comparison\n",
    "\n",
    "| Aspect | OpenAI | Anthropic |\n",
    "|--------|--------|-----------|\n",
    "| Tool wrapper | `{\"type\": \"function\", \"function\": {...}}` | Direct tool object |\n",
    "| Parameters field | `parameters` | `input_schema` |\n",
    "| Tool call ID | `tool_calls[].id` | `content[].id` (when type=tool_use) |\n",
    "| Arguments | `tool_calls[].function.arguments` (string) | `content[].input` (dict) |\n",
    "| Stop reason | `finish_reason: \"tool_calls\"` | `stop_reason: \"tool_use\"` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Multi-Turn Conversations <a id='multi-turn'></a>\n",
    "\n",
    "Real applications require sending tool results back to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Complete multi-turn flow with OpenAI\n",
    "\n",
    "def complete_with_tools(user_message: str, tools: list, max_iterations: int = 5):\n",
    "    \"\"\"\n",
    "    Complete a conversation, handling any tool calls.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        print(f\"\\n--- Iteration {i+1} ---\")\n",
    "        \n",
    "        # Make API call\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        message = response.choices[0].message\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        \n",
    "        print(f\"Finish Reason: {finish_reason}\")\n",
    "        \n",
    "        # If no tool calls, we're done\n",
    "        if finish_reason == \"stop\" or not message.tool_calls:\n",
    "            print(f\"Final Response: {message.content}\")\n",
    "            return message.content\n",
    "        \n",
    "        # Add assistant message with tool calls\n",
    "        messages.append(message)\n",
    "        \n",
    "        # Process each tool call\n",
    "        for tool_call in message.tool_calls:\n",
    "            func_name = tool_call.function.name\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"Calling: {func_name}({args})\")\n",
    "            \n",
    "            # Execute the function\n",
    "            if func_name in FUNCTIONS:\n",
    "                result = FUNCTIONS[func_name](**args)\n",
    "            else:\n",
    "                result = f\"Error: Unknown function {func_name}\"\n",
    "            \n",
    "            print(f\"Result: {result}\")\n",
    "            \n",
    "            # Add tool result to messages\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": json.dumps(result) if isinstance(result, (dict, list)) else str(result)\n",
    "            })\n",
    "    \n",
    "    return \"Max iterations reached\"\n",
    "\n",
    "# Test it\n",
    "result = complete_with_tools(\n",
    "    \"What's the weather in Tokyo? Also, what's 15 * 23?\",\n",
    "    openai_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points for Multi-Turn\n",
    "\n",
    "1. **Add the assistant message** (including tool_calls) to history\n",
    "2. **Add tool results** with matching `tool_call_id`\n",
    "3. **Continue until** finish_reason is \"stop\"\n",
    "4. **Set a max iterations** limit to prevent infinite loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Error Handling <a id='errors'></a>\n",
    "\n",
    "Robust tool handling requires proper error management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Error handling patterns\n",
    "\n",
    "def safe_execute_tool(func_name: str, args: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Safely execute a tool with error handling.\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"success\": False,\n",
    "        \"result\": None,\n",
    "        \"error\": None\n",
    "    }\n",
    "    \n",
    "    # Check if function exists\n",
    "    if func_name not in FUNCTIONS:\n",
    "        result[\"error\"] = f\"Unknown function: {func_name}\"\n",
    "        return result\n",
    "    \n",
    "    # Try to execute\n",
    "    try:\n",
    "        func = FUNCTIONS[func_name]\n",
    "        output = func(**args)\n",
    "        result[\"success\"] = True\n",
    "        result[\"result\"] = output\n",
    "    except TypeError as e:\n",
    "        result[\"error\"] = f\"Invalid arguments: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        result[\"error\"] = f\"Execution error: {str(e)}\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test error handling\n",
    "print(\"Valid call:\")\n",
    "print(safe_execute_tool(\"get_weather\", {\"location\": \"Paris\"}))\n",
    "\n",
    "print(\"\\nUnknown function:\")\n",
    "print(safe_execute_tool(\"unknown_func\", {}))\n",
    "\n",
    "print(\"\\nMissing argument:\")\n",
    "print(safe_execute_tool(\"get_weather\", {}))  # Missing required 'location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Validation before execution\n",
    "\n",
    "def validate_arguments(func_name: str, args: dict, tool_defs: list) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Validate arguments against tool definition.\n",
    "    \"\"\"\n",
    "    # Find the tool definition\n",
    "    tool_def = None\n",
    "    for tool in tool_defs:\n",
    "        if tool[\"function\"][\"name\"] == func_name:\n",
    "            tool_def = tool[\"function\"]\n",
    "            break\n",
    "    \n",
    "    if not tool_def:\n",
    "        return False, f\"Unknown tool: {func_name}\"\n",
    "    \n",
    "    params = tool_def.get(\"parameters\", {})\n",
    "    required = params.get(\"required\", [])\n",
    "    properties = params.get(\"properties\", {})\n",
    "    \n",
    "    # Check required parameters\n",
    "    for req in required:\n",
    "        if req not in args:\n",
    "            return False, f\"Missing required parameter: {req}\"\n",
    "    \n",
    "    # Check enum values\n",
    "    for key, value in args.items():\n",
    "        if key in properties:\n",
    "            prop = properties[key]\n",
    "            if \"enum\" in prop and value not in prop[\"enum\"]:\n",
    "                return False, f\"Invalid value for {key}: {value}. Must be one of {prop['enum']}\"\n",
    "    \n",
    "    return True, \"Valid\"\n",
    "\n",
    "# Test validation\n",
    "print(\"Valid arguments:\")\n",
    "print(validate_arguments(\"get_weather\", {\"location\": \"Paris\", \"unit\": \"celsius\"}, openai_tools))\n",
    "\n",
    "print(\"\\nMissing required:\")\n",
    "print(validate_arguments(\"get_weather\", {\"unit\": \"celsius\"}, openai_tools))\n",
    "\n",
    "print(\"\\nInvalid enum:\")\n",
    "print(validate_arguments(\"get_weather\", {\"location\": \"Paris\", \"unit\": \"kelvin\"}, openai_tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Using Our LLM Client <a id='client'></a>\n",
    "\n",
    "Our `LLMClient` abstracts away provider differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Use our unified client\n",
    "\n",
    "from src.llm_client import LLMClient, Message\n",
    "from src.tool_registry import ToolRegistry, Tool\n",
    "\n",
    "# Create client\n",
    "client = LLMClient(provider=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create tools\n",
    "registry = ToolRegistry()\n",
    "\n",
    "registry.register(Tool(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get current weather for a location\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "    },\n",
    "    function=get_weather\n",
    "))\n",
    "\n",
    "print(\"Client and tools ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDED: Use client with tools\n",
    "\n",
    "# Make request with tools\n",
    "response = client.chat(\n",
    "    messages=[Message(role=\"user\", content=\"What's the weather in Berlin?\")],\n",
    "    tools=registry.to_openai_format()\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(f\"  Content: {response.content}\")\n",
    "print(f\"  Has tool calls: {response.has_tool_calls}\")\n",
    "\n",
    "if response.has_tool_calls:\n",
    "    for tc in response.tool_calls:\n",
    "        print(f\"\\nTool Call: {tc.name}\")\n",
    "        print(f\"  Arguments: {tc.arguments}\")\n",
    "        \n",
    "        # Execute using registry\n",
    "        result = registry.execute(tc.name, **tc.arguments)\n",
    "        print(f\"  Result: {result.result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Exercises <a id='exercises'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Multi-Tool Request\n",
    "\n",
    "Ask a question that requires multiple tools and handle all the calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Send a request like \"Compare the weather in Paris and London\"\n",
    "# Handle all tool calls and get the final response\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Add a New Tool\n",
    "\n",
    "Add a `get_time` tool that returns the current time in a timezone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a get_time tool\n",
    "# Parameters: timezone (string)\n",
    "# Returns current time in that timezone\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Error Recovery\n",
    "\n",
    "Implement a flow that gracefully handles tool errors and asks the LLM to try a different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement error recovery\n",
    "# If a tool fails, send the error back to the LLM\n",
    "# Let it decide what to do next\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Checkpoint <a id='checkpoint'></a>\n",
    "\n",
    "Before moving on, verify:\n",
    "\n",
    "- [ ] You understand both OpenAI and Anthropic tool formats\n",
    "- [ ] You can handle multi-turn conversations with tools\n",
    "- [ ] You implemented proper error handling\n",
    "- [ ] You can use our LLMClient with tools\n",
    "- [ ] You completed at least 2 exercises\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll build **ReAct Agents** - putting together everything we've learned to create agents that can reason and act!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "1. **OpenAI** uses `tools` with `type: function` wrapper\n",
    "2. **Anthropic** uses direct tool objects with `input_schema`\n",
    "3. **Multi-turn** requires adding tool results back to messages\n",
    "4. **Error handling** is essential for production systems\n",
    "5. **Our LLMClient** abstracts provider differences\n",
    "\n",
    "**Production Checklist:**\n",
    "- Validate arguments before execution\n",
    "- Handle unknown functions gracefully\n",
    "- Set iteration limits\n",
    "- Log all tool calls for debugging\n",
    "- Return useful error messages to the LLM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
